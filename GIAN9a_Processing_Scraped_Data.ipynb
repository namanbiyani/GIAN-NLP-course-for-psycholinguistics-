{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GIAN 9a: Processing Scraped Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing the data\n",
    "We will import the data that we have scraped from Language Log. This data has been stored in a *json* file, giving structured access to the different elements of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import en_core_web_sm\n",
    "nlp=en_core_web_sm.load(disable=[\"parser\", \"tagger\", \"ner\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"language_log.json\", \"r\", encoding=\"utf-8\") as f_in:\n",
    "    posts=json.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at what the structured data for a post looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for comment in posts[10]['comments']:\n",
    "    print(comment[\"author\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a simple function to extract the text data (title, entry, and comment bodies) from the post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(post):\n",
    "    output=[]\n",
    "    output.append(post['entry'])\n",
    "    for comment in post.get('comments',[]):\n",
    "        output.append(comment['body'])\n",
    "    return(\"\\n\".join(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a sanity check\n",
    "extract_text(posts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tokenizing the corpus\n",
    "We will first take all of the posts and make them into one big blob of text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try this first on 100 posts. We can remove the limit later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_blob=\"\\n\".join([extract_text(post) for post in posts[:100]])\n",
    "# increase the maximum allowed size for one document\n",
    "nlp.max_length=len(corpus_blob)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=nlp(corpus_blob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our corpus has now been tokenized, and we can answer some basic questions\n",
    "\n",
    "How many tokens are in the corpus ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nwords=len(corpus)\n",
    "print(nwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some basic statistics about the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_lengths=[len(word) for word in corpus] # lengths of all the words\n",
    "mean_word_length=sum(word_lengths)/nwords\n",
    "min_word_length=min(word_lengths)\n",
    "max_word_length=max(word_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Mean word length:\", mean_word_length)\n",
    "print(\"Shortest word length:\", min_word_length)\n",
    "print(\"Longest word length:\", max_word_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect words of different lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_of_length(words, length):\n",
    "    result=[word.lower_ for word in words if len(word)==length]\n",
    "    return(set(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"words\", words_of_length(corpus, 690))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Counting words\n",
    "\n",
    "Word frequencies are the basic building blocks of many text mining techniques. Once text has been tokenized it becomes very easy to count how often each particular word occurs in that text.\n",
    "\n",
    "It is good to remember that:\n",
    "\n",
    "+ We call each particular word a word *type*\n",
    "+ We call every occurrence of a word a word *token*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from math import *\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_wf=Counter([word.orth_ for word in corpus]) # frequency of the word in the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corpus_wf.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make all words lowercase and get rid of punctuation!\n",
    "corpus_wf=Counter([word.lower_ for word in corpus if re.search(\"\\w+\", word.lower_)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_wf.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make relative frequencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=sum(corpus_wf.values())\n",
    "corpus_fpm=Counter({word: (frequency/n*1E6) for word, frequency in corpus_wf.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_fpm.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And zipf values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=sum(corpus_wf.values())\n",
    "ntypes=len(corpus_wf.values())\n",
    "corpus_zipf = Counter({word: log10((f+1)/(n+ntypes)*1E9) for word, f in corpus_wf.items()}) #log 10 frequency per billion words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_zipf.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the frequencies in descending order for the graph\n",
    "frequencies=sorted(corpus_zipf.values(),reverse=True)\n",
    "ranks=list(range(len(frequencies)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from math import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ranks, frequencies)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
